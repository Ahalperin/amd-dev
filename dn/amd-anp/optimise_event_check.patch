diff --git a/src/net_ib.cc b/src/net_ib.cc
index 8e4ae8e..8449634 100644
--- a/src/net_ib.cc
+++ b/src/net_ib.cc
@@ -47,10 +47,19 @@ extern int64_t ncclParamDmaBufEnable();
 #define NCCL_NET_USE_WRITE_OP                (void *)0x1
 #define ANP_CTS_QP_SLOT_INVALID              0xFF
 
-//#define ANP_DEBUG_TRACE_EN
+#define ANP_DEBUG_TRACE_EN
 #define CTS_INLINE_ENABLED
 #define CTS_RCVR_OFFLOAD_ENABLED
 
+/* Enable adaptive backoff in polling loop to reduce CPU usage */
+#define ANP_ADAPTIVE_BACKOFF_ENABLED
+
+/* Adaptive backoff configuration parameters */
+#define ANP_BACKOFF_THRESHOLD        100    /* Empty polls before starting backoff */
+#define ANP_BACKOFF_PAUSE_THRESHOLD  10     /* Additional polls before CPU pause */
+#define ANP_BACKOFF_YIELD_THRESHOLD  100    /* Additional polls before yield */
+#define ANP_BACKOFF_SLEEP_THRESHOLD  1000   /* Additional polls before sleep */
+
 #define MAX_INLINE_DATA_SIZE 24
 #define ENABLE_TIMER 0
 
@@ -2840,15 +2849,71 @@ ncclResult_t anpNetFlush(void* recvComm, int n, void** data, int* sizes, void**
   return ncclSuccess;
 }
 
-#define ANP_CQ_POLL_MAX_EVENT        16
+#define ANP_CQ_POLL_MAX_EVENT        32
 #define HCA_NAME(req, index) ((req)->devBases[(index)]->pd->context->device->name)
 
+#ifdef ANP_ADAPTIVE_BACKOFF_ENABLED
+/* Adaptive backoff state for polling optimization.
+ * Reduces CPU usage during idle periods while maintaining low latency.
+ */
+struct anp_backoff_state {
+  int empty_poll_count;
+};
+
+/* Reset backoff state when activity detected */
+static inline void anp_backoff_reset(struct anp_backoff_state* state) {
+  state->empty_poll_count = 0;
+}
+
+/* Apply backoff strategy based on consecutive empty polls */
+static inline void anp_backoff_apply(struct anp_backoff_state* state) {
+  state->empty_poll_count++;
+  
+  if (state->empty_poll_count <= ANP_BACKOFF_THRESHOLD) {
+    /* Fast path: no backoff, tight polling for low latency */
+    return;
+  }
+  
+  int backoff_level = state->empty_poll_count - ANP_BACKOFF_THRESHOLD;
+  
+  if (backoff_level < ANP_BACKOFF_PAUSE_THRESHOLD) {
+    /* Level 1: CPU pause instruction (lightest backoff ~10 cycles) */
+    #if defined(__x86_64__)
+    _mm_pause();
+    #elif defined(__aarch64__)
+    __asm__ __volatile__("yield" ::: "memory");
+    #endif
+  }
+  else if (backoff_level < ANP_BACKOFF_YIELD_THRESHOLD) {
+    /* Level 2: Yield to scheduler (moderate backoff ~1us) */
+    sched_yield();
+  }
+  else if (backoff_level < ANP_BACKOFF_SLEEP_THRESHOLD) {
+    /* Level 3: Short sleep (heavier backoff ~1-10us) */
+    usleep(1);
+  }
+  else {
+    /* Level 4: Longer sleep for very long waits */
+    usleep(10);
+  }
+}
+#endif /* ANP_ADAPTIVE_BACKOFF_ENABLED */
+
 ncclResult_t anpNetTest(void* request, int* done, int* sizes) {
   struct ncclIbRequest *r = (struct ncclIbRequest*)request;
   *done = 0;
+  
+#ifdef ANP_ADAPTIVE_BACKOFF_ENABLED
+  /* Thread-local backoff state to avoid cache line bouncing between threads */
+  static __thread struct anp_backoff_state backoff_state = {0};
+#endif
+  
   while (1) {
     NCCLCHECK(ncclIbStatsCheckFatalCount(&r->base->stats,__func__));
     if (r->events[0] == 0 && r->events[1] == 0 && r->events[2] == 0 && r->events[3] == 0) {
+#ifdef ANP_ADAPTIVE_BACKOFF_ENABLED
+      anp_backoff_reset(&backoff_state);
+#endif
       TRACE(NCCL_NET, "r=%p done", r);
       *done = 1;
       if (sizes && r->type == NCCL_NET_IB_REQ_RECV) {
@@ -2877,6 +2942,12 @@ ncclResult_t anpNetTest(void* request, int* done, int* sizes) {
         );
         if (wrDone == 0) { TIME_CANCEL(3); } else { TIME_STOP(3); }
         if (wrDone == 0) continue;
+        
+#ifdef ANP_ADAPTIVE_BACKOFF_ENABLED
+        /* Reset backoff counter on successful completion */
+        anp_backoff_reset(&backoff_state);
+#endif
+        
         for (int w=0; w<wrDone; w++) {
           struct ibv_wc *wc = wcs+w;
           if (wc->status != IBV_WC_SUCCESS) {
@@ -2950,7 +3021,13 @@ ncclResult_t anpNetTest(void* request, int* done, int* sizes) {
     }
 
     // If no CQEs found on any device, return and come back later
-    if (totalWrDone == 0) return ncclSuccess;
+    if (totalWrDone == 0) {
+#ifdef ANP_ADAPTIVE_BACKOFF_ENABLED
+      /* Apply adaptive backoff to reduce CPU usage during idle periods */
+      anp_backoff_apply(&backoff_state);
+#endif
+      return ncclSuccess;
+    }
   }
 }